<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>ANPR Mobile</title>
    <script src='https://unpkg.com/tesseract.js@v2.1.0/dist/tesseract.min.js'></script>
    <script src="https://docs.opencv.org/4.5.2/opencv.js"></script>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            margin: 0;
            padding: 10px;
            background: #f5f5f5;
            display: flex;
            flex-direction: column;
            align-items: center;
            min-height: 100vh;
        }

        #videoContainer {
            position: relative;
            width: 100%;
            max-width: 100%;
            margin: 10px 0;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        #videoCanvas {
            width: 100%;
            height: auto;
            display: block;
        }

        #plateList {
            list-style: none;
            padding: 0;
            margin: 20px 0;
            width: 100%;
            max-width: 400px;
        }

        .plate-item {
            background: white;
            margin: 8px 0;
            padding: 15px;
            border-radius: 8px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
            font-size: 1.1em;
            /* font-weight: bold; */
            text-align: center;
            animation: slideIn 0.3s ease;
        }

        @keyframes slideIn {
            from { transform: translateY(20px); opacity: 0; }
            to { transform: translateY(0); opacity: 1; }
        }

        /* Hidden elements */
        #videoElement, #processedCanvas, #licensePlateCanvas {
            display: none;
        }

        /* Mobile optimization */
        @media (max-width: 480px) {
            body {
                padding: 5px;
            }
            
            .plate-item {
                font-size: 1em;
                padding: 12px;
            }
        }
    </style>
</head>
<body>
    <div id="videoContainer">
        <video id="videoElement" autoplay playsinline></video>
        <canvas id="videoCanvas"></canvas>
        <canvas id="processedCanvas"></canvas>
        <canvas id="licensePlateCanvas"></canvas>
    </div>
    <ul id="plateList"></ul>

    <script>
        const videoElement = document.getElementById('videoElement');
        const videoCanvas = document.getElementById('videoCanvas');
        const plateList = document.getElementById('plateList');
        const videoCtx = videoCanvas.getContext('2d');
        
        let currentPlate = {
            text: null,
            rect: null,
            timestamp: 0
        };
        const detectedPlates = new Set();
        let isProcessing = false;

        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { 
                    facingMode: 'environment',
                    width: { ideal: 1280 },
                    height: { ideal: 720 }
                }
            });
            videoElement.srcObject = stream;
            
            return new Promise(resolve => {
                videoElement.onloadedmetadata = () => {
                    videoElement.play();
                    videoCanvas.width = videoElement.videoWidth;
                    videoCanvas.height = videoElement.videoHeight;
                    resolve();
                };
            });
        }

        function detectLicensePlateRegion(src) {
            let gray = new cv.Mat();
            let edges = new cv.Mat();
            let contours = new cv.MatVector();
            let hierarchy = new cv.Mat();

            // Preprocessing pipeline
            cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
            cv.GaussianBlur(gray, gray, new cv.Size(5, 5), 0);
            cv.equalizeHist(gray, gray);
            
            // Edge detection (made with GPT-4o)
            cv.Canny(gray, edges, 50, 150);
            cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

            let licensePlateContour = null;
            for (let i = 0; i < contours.size(); i++) {
                let contour = contours.get(i);
                let area = cv.contourArea(contour);
                let approx = new cv.Mat();
                cv.approxPolyDP(contour, approx, 0.02 * cv.arcLength(contour, true), true);

                if (approx.rows === 4 && area > 500 && area < 10000) {
                    licensePlateContour = approx;
                    break;
                }
                approx.delete();
            }

            // Cleanup
            gray.delete();
            edges.delete();
            contours.delete();
            hierarchy.delete();

            return licensePlateContour;
        }

        // processFrame (made with DeepSeek-R1 and GPT-4o)
        async function processFrame() {
            if (isProcessing) return;
            isProcessing = true;

            try {
                videoCtx.drawImage(videoElement, 0, 0);
                let src = cv.imread(videoCanvas);
                
                let contour = detectLicensePlateRegion(src);
                if (contour) {
                    let rect = cv.boundingRect(contour);
                    let aspectRatio = rect.width / rect.height;
                    
                    if (aspectRatio >= 2 && aspectRatio <= 5) {
                        currentPlate.rect = rect;
                        currentPlate.timestamp = Date.now();
                        
                        // OCR Processing
                        let roi = src.roi(rect);
                        let processed = new cv.Mat();
                        cv.cvtColor(roi, processed, cv.COLOR_RGBA2GRAY);
                        cv.adaptiveThreshold(processed, processed, 255, 
                            cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11, 2);
                        
                        let canvas = document.createElement('canvas');
                        cv.imshow(canvas, processed);
                        
                        const { data: { text } } = await Tesseract.recognize(canvas, 'eng', {
                            tessedit_char_whitelist: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',
                            tessedit_pageseg_mode: 'single_line'
                        });
                        
                        const cleanedText = text.replace(/[^A-Z0-9]/g, '').trim();
                        if (/^[A-Z]{1,2}\d{1,4}[A-Z]{1,3}$/.test(cleanedText)) {
                            currentPlate.text = cleanedText;
                            if (!detectedPlates.has(cleanedText)) {
                                addToPlateList(cleanedText);
                                detectedPlates.add(cleanedText);
                            }
                        }
                        
                        processed.delete();
                        roi.delete();
                    }
                }
                src.delete();
            } catch (error) {
                console.error('Processing error:', error);
            }
            isProcessing = false;
        }

        // Bounding Box made with (Claude-Sonnet-3.5 and GPT-4o)
        function drawBoundingBox() {
            videoCtx.clearRect(0, 0, videoCanvas.width, videoCanvas.height);
            videoCtx.drawImage(videoElement, 0, 0);
            
            if (currentPlate.rect && (Date.now() - currentPlate.timestamp) < 1000) {
                const rect = currentPlate.rect;
                
                // Draw bounding box
                videoCtx.beginPath();
                videoCtx.rect(rect.x, rect.y, rect.width, rect.height);
                videoCtx.lineWidth = 3;
                videoCtx.strokeStyle = '#00C853';
                videoCtx.stroke();
                
                // Draw text with background
                videoCtx.fillStyle = '#00C853';
                videoCtx.font = 'bold 24px Arial';
                videoCtx.textBaseline = 'bottom';
                
                // Text background
                const text = currentPlate.text || 'Detecting...';
                const textWidth = videoCtx.measureText(text).width;
                videoCtx.fillStyle = 'rgba(0, 0, 0, 0.7)';
                videoCtx.fillRect(
                    rect.x - 5,
                    rect.y - 34,
                    textWidth + 10,
                    30
                );
                
                // Text
                videoCtx.fillStyle = '#ffffff';
                videoCtx.fillText(text, rect.x, rect.y - 10);
            }
            
            requestAnimationFrame(drawBoundingBox);
        }

        function addToPlateList(plateNumber) {
            const listItem = document.createElement('li');
            listItem.textContent = plateNumber;
            listItem.className = 'plate-item';
            plateList.insertBefore(listItem, plateList.firstChild);
            
            if (plateList.children.length > 10) {
                plateList.removeChild(plateList.lastChild);
            }
        }

        async function main() {
            await Promise.all([
                new Promise(resolve => cv.onRuntimeInitialized = resolve),
                Tesseract.ready
            ]);
            
            await setupCamera();
            requestAnimationFrame(drawBoundingBox);
            setInterval(processFrame, 500);
        }

        // Handle mobile orientation changes
        window.addEventListener('resize', () => {
            videoCanvas.width = videoElement.videoWidth;
            videoCanvas.height = videoElement.videoHeight;
        });

        main().catch(console.error);
    </script>
</body>
</html>